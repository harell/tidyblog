---
title: 'Data Tests: Separating between Data Sources and the Rest'
author: Harel Lustiger
date: '2020-02-22'
slug: data-tests-separating-between-data-sources-and-the-rest
draft: true
categories:
  - R
  - Software Architecture
tags:
  - plugin architecture
  - data sources
  - small design up front
bibliography: [references-talks.bib]
biblio-style: apalike
link-citations: yes  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  out.width = "100%"
)
```

## Abstract

Data science projects in commercial companies often experience a challenge
arising from evolving data sources. As the project progresses, new signals and
information sources are added incrementally. In practice, when the data source
changes, it creates a need to change the application source code.

With **no design up front**, some application modules, such as a dashboard or a
machine learning model, unwittingly become dependent on the data source. In this
case, accommodating the evolving data source is not simply a matter of changing
the code related to the data source. Rather, preserving the rest of the existing
application in a working condition involves further code changes in distant
elements of the application.

An alternative way of dealing with evolving data sources is to introduce a
**small design up front**. Such design lets data scientists manage the source
code dependencies throughout the project life-cycle.

This post suggests a design that <mark>(1) separates data sources from analytic
applications and (2) restricts analytic applications from knowing about the data
sources</mark>.

While the evolving data sources challenge is programming language agnostic, this
post demonstrates an implementation of the suggested design in R.

## Helping our clients by fitting a solution to their needs

### Getting to know our client 

Our client is Euel Cheatam the Merceduce dealership manager.

```{r Eual-during-mentorship-session} 
knitr::include_graphics('https://i.imgur.com/IcwSkWa.png')
```

Eual has been working in Mercedes dealership as a car salesman for the last 7
years. Today, Eual serves as the dealership manager. His main duty is to ensure
a profitable, complaint, and effective dealership.

- Eual **thinks** that a professional car salesperson needs to answer prospects
queries quickly and accurately.
- Eual **sees** that it takes new hires several months to master the
dealership’s cars specifications. During these months new-hires convert fewer
prospects into clients; this causes new hires to get demotivated; which leads to
fewer sales -- it's a vicious cycle.
- Eual **feels** obligated to provide resources that will enable everyone to
succeed as a salesperson, regardless of their work tenure.
- Eual **does** not have enough free time slots in his calendar to accommodate
daily mentoring for all the dealership salespeople.

### The proposed solution is a weekly fact sheet with popular Q&A  

```{r car-stat-sheet} 
knitr::include_graphics('https://i.imgur.com/CMbZ8h7.png')
```

<!-- Position Statement -->

For the car salespeople who work at Mercedes dealership, the *Factcedes™* is a
weekly email service that provides a succinct and readable fact sheet with
popular Q&A about the dealership vehicles. Unlike water cooler talks, our
product has been carefully formulated and evaluated against veterans and is
distributed regularly.

## 1^st^ iteration: developing a data-driven app without real data

### Moving from ideation to implementation, data scientists encounter real-world impediments 

```{r 1st-world-problems} 
knitr::include_graphics('https://i.imgur.com/TAcOHZO.png')
```

Data scientists encounter many 1^st^ world problems during the development
process; Unavailable database is one of them. A slow database is another.

### Generate dataset assumption triplet

<!-- The data source of the data-driven app must support the intent of the analytic app. -->

In many cases, including the case in hand, the analytic app can be satesfied
with a tidy data table in its input.

A tidy data table [@wickham2016r, ch. 12] follows a consistent tabular format
where each variable is a column and each observation is a row.

The data scientist wants the tidy data table to support all of necessary
variables required by the analytic app, but does not know what all those
variables are. However, the data scientist does know the basic intent of the
analytic app.

<!-- tidy data table leaves heavy data wrangling tasks outside the
responsibility of the analytic app. -->

Start by making **assumption triplets** about what information the user needs to
see:

* **Primary Key** represents car models;
* **Target variable** is the price; and
* **Salient features** include gear, and mpg.

```{r tidy-table, eval = FALSE}
set.seed(1238)
n <- 6
tibble::tibble(
    uid = head(1:26, n),
    x1 = head(letters, n),
    x2 = head(LETTERS, n),
    y = rpois(n, lambda = 5)
)
```

### Convert assumptions to assertions with data-tests

* Data-tests are assertions that ensure [data
integrity](https://en.wikipedia.org/wiki/Data_integrity), mainly, they concern
the data existance and structure.
* Data tests are like clauses in a contract. 
* The analytic application dictates the clauses.
* The analytic application is dependent only on the clauses.

```{r data-tests, echo = TRUE, eval = FALSE}
# data-tests.R
## 1. Check if the dataset exists
stopifnot(exist("cars_data"), is.data.frame(cars_data))
  
## 2. Check if the necessary columns exist
expected_cols <- c("car_model", "price", "gear", "mpg")
stopifnot(all(expected_cols %in% colnames(cars_data)))
  
## 3. Check if the records are unique
is.distinct <- function(x) dplyr::n_distinct(x) == length(x)
stopifnot(is.distinct(cars_data$car_model))
```

### Implement data source plugins

#### Quick glimpse over the `mtcars` dataset

```{r}
mtcars %>% 
    head() %>% 
    knitr::kable(caption = "The first 6 car models from `datasets::mtcars`", 
                 row.names = TRUE, digits = 0) %>% 
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = TRUE)
```

#### Generate synthetic data[^synthetic-data] plugin

```{r data-source, echo = TRUE, eval = FALSE}
get_cars_data <- function(){
  ## 1. Generate records 
  data(mtcars, package = "datasets")
  cars_data <- mtcars %>% tibble::rownames_to_column("car_model")
  
  ## 2. Generate price
  set.seed(2020)
  price <- runif(n = nrow(cars_data), min = 41, max = 75)
  cars_data <- cars_data %>% tibble::add_column(price = price)
  
  ## Run data-tests
  source("data-tests.R")
  return(cars_data)
}
```

Notice that without conforming to data-tests, the data source does not come into
existence. That means the data source is dependent on data-tests. Recall that
the assertions in data-tests are dictated by the intent of the analytic app. It
is these assertions that make the data source module knows about the analytic
app.

### Develop analytic applications

```{r synthetic-data, echo = TRUE, eval = FALSE}
# app.R
## 1. Get the data
source("data-source.R")
cars_data <- get_cars_data()
  
## 2. Render booklet
print(cars_data %>% dplyr::select(car_model, mpg, gear, price))
boxplot(price ~ mpg + gear, cars_data)  
```

## Why, how and what have we done

### Recall why we have separated the data source from the rest

Any data-driven application has two essential parts: *data source* and *analytic
app*. Moreover, in any system design the data source does not know about the analytic app. That means that the data source is indepedent of the analytic app.

With no design up front, 

Without care the dependency structure is...

The suggested system design:

(1) Divides and encapsulates those parts into modules; 
(2) Separates both parts by introducing an intermediate module dubbed
*data-tests*; and
(3) Dictates that both parts must depend on the data-tests module.  

The primary advantage of using data-tests is that <mark>the data source module
and the analytic app module do not know anything of each other</mark>. This
allows those modules to evolve frequently and independently.


### Recall how we have separated the data source from the rest

Firstly, we took the analytic app point of view. The app expects a tidy data
table with a specific structure. 

Second, we asserted the app expectations regarding the data in the form of a
policy named data-tests.

Third, we implemented a data source that conforms to data-tests.

### Recall what have separated the data source from the rest

<!-- ## 2^nd^ iteration: implementing customer feedback -->

<!-- ## 3^rd^ iteration: deploying the application with real data -->

## References

<!-- Footnotes -->

[^synthetic-data]: A synthetic datasetis contains data that is artificially
created rather than being generated by actual events.
